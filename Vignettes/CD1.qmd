---
title: "Aitchison and Ng"

format: pdf

editor: source
---

## The paper

Aitchison and Ng discuss the use of compositional data tools to try and understand the contents of cows milk. The data are taken from there paper and consist of measurements of the compositin of milk from a number of dairy cows. They state:

In an attempt to improve the quality of cow’s milk, milk from each of thirty cows was assessed by dietary composition before and after a strictly controlled dietary and hormonal regime over a period of eight weeks. Although seasonal variations in milk quality could probably be regarded as negligible over this period a control group of thirty cows was kept under the same conditions but on the standard regime. The sixty cows were of course allocated to control and treatment groups at random. Table 1 provides a set of typical before and after results for ten cows, five in the control group and five in the treatment group, showing the protein, milk fat, carbohydrate, calcium, sodium and potassium proportions by weight of total dietary content. The full data set is obtainable in Appendix Table 1. The purpose of the experiment is to determine whether the new regime has produced any significant change in the milk composition...

The key features are

-   **Pr** : Proportion of protein.
-   **Mf** : Proportion of milk fat.
-   **Ch** : Proportion of carbohydrate.
-   **Ca** : Proportion of calcium.
-   **Na** : Proportion of sodium.
-   **K** : Proportion of potassium.
-   **Group** : Which group: Contol, Before and After

The control group consists of 30 cows, each with a before (rows 1 to 30) and an after (rows 31 to 60) measurement. The original treated data also consisted of 30 cows with before and after, however the paper the data was extracted from only had 24 cows in the after group. We hope that these are the first 24 and treat them as such.

There are a number of interesting comparisons that can be made, and different ways in which estimates can be developed and hypotheses tested.  First, we can compare the treated and untreated cows at the beginning. Since cows were randomly assigned to the two groups and tests should yield a null result and find no difference.  Comparing the control cows between the two time points allows us to estimate the seasonal effect using within cow comparisons, but it could also be done by treating the two time points seperately.

The treated cows can be compared before and after, also either as a paired T test or as a two sample T test. Here the difference would be a combination of the seasonal difference as well as the treatment difference. And one might try to subtract, in some way the seasonal effect estimated for the control group.  A similar approach would be to subtract the seasonal difference from each cow (perhaps sampling from a distribution that was consistent with what was observed for the control group) 
and then comparing to the treatment group at the second time point, after the treatment has had an effect. 


## Loading

We next want to load the libraries and the data so that we can explore some of the methods that are being described and understand how they impact the analysis.  Below are three simple helper functions that implement a geometric mean, the closure of a set of numbers with respect to a unit sum, and a vector version of the inverse of the additive log ratio transformation.  

We load the compositionalAnalysis package to get additional datasets.

```{r, message=FALSE, warning=FALSE}
library(compositionalAnalysis)
#not sure where to get the Hotelling's test 
library(rrcov)

##a helper function
geometric_mean <- function(x) {
  if (any(x <= 0)) {
    stop("Geometric mean is only defined for positive numbers.")
  }
  exp(mean(log(x)))
}

Closure = function(x) {
  if(any(x < 0 ) ) stop("only positive values allowed")
  return(as.numeric(x/sum(x)))
}

## given a D-1 dimensional vector compute the alr inverse function on a vector
##the alrInv function in robCompositions wants to inverse a data matrix.
alrInv = function(x) { Closure(c(exp(x),1))}


```

We begin with Aitchison's hongite example, with data extracted from the Table 1.1.1 of the paper. This is mostly to ensure that we are capturing the right quantities.

```{r hongite}

hongite = read.delim("data/HongiteTab111", sep=" ", head=F)
##drop col 1, just the observation number
hongite = hongite[,-1]
colnames(hongite) = LETTERS[1:5]

hongitealr = addLR(hongite)

##values from the paper - we should see agreement
#  0.1386 0.2641 -0.2233 0.1214
#  0.2641 0.6490 -0.7020 0.1444
# -0.2233 -0.7020 0.9476 0.0116
#  0.1214 0.1444 0.0116 0.1871
round(cov(hongitealr$x.alr), digits=3)

## values taken from the paper - should be in agreement
## this calculates the variance of each of the log(x_i)/log(x_j) pairs
## and is equivalent to the values above (in that one can be obtained from the other
## using matrix methods).
## NOTE: it is not symmetric

#  0 0.2593 1.5329 0.0828 0.1386
#  0.2593 0 3.0007 0.5473 0.6490
#  1.5329 3.0007 0 1.1115 0.9476
#  0.0828 0.5473 1.1115 0 0.1871
#  0.1386 0.6490 0.9476 0.1871 0

round(variation(hongitealr$x.alr, method = "Pairwise"), digits=4)

##we can compute the geometric means in the closure space
##this can also be done using the aLR values and representing them in the appropriate simplex.
round(Closure(apply(hongite,2, geometric_mean)), digits=3)


```


We will load up the milk composition data from Aithchison and Ng and try to do some of the analyses that they report on. Since the data are incomplete we will only work with the first 24 of the Before and After samples. We need to define the notion of closure.

The sample space associated with D-part compositions is the unit simplex:

$$
S^D = \{ [x_1, \ldots, x_D] , x_i \geq 0, x_1 + \cdots + x_D = 1 \}
$$

And so any element in this sample space needs to comply with those requirements. The *closure* operator takes a vector of positive values as input and returns the vector normalized to sum to one.

Next we define the notion of a perturbation. For any two D-part compositions, $x$ and $y$, with $x, y \in S^D$, we can define \$ x \oplus y\$ as $$
 x \oplus y = [x_1 y_1, \ldots, x_D y_D]/(x_1 y_1 + \cdots x_D y_D) = C[x_1 y_1, \ldots, x_D y_D]
$$ For our problems we want to find the perturbation, $p$, that transforms one obesrvation $x_B$, a before measurement, into a second observation, $x_A$, an after measurement. We want $p$ such that $x_A = p \oplus x_B$. That is found by the inverse operation,

\$\$

p = x_B , \Theta , x_A = C\[x\_{A1}/x\_{B1}, \ldots, x\_{AD} / x\_{BD}\]

\$\$

```{r}
data("MilkComposition")

## since there are 30 cows, obs 1 and 31 are on the same cow
## and this finds the perturbation.

Closure(MilkComposition[31,1:6]/ MilkComposition[1,1:6])
```

Above we have show how to compute the perturbation, $p$ that would be applied to the before measurement (observation 1) to yield the after measurement - observation 31, for the first cow.

Now, we approach each of the inference questions from Aitchison and Ng. **Question 1** Is there any evidence of seasonal change in milk composition, in other words is there any evidence of differences in the milk compositions of the control group between the beginning and end of the trial? Phrased as a compositional hypothesis this is simply a question of whether the centre of the control group perturbations is the identity perturbation. A standard way of testing such a hypothesis is through the logratio analysis of Aitchison (1986). Transformed into logratio terms this is simply asking whether the mean of the additive logratio vectors $$
   q = alr(p) = [\log(p_1/p_6), \ldots, \log(p_5/p_6)]
$$

is a zero vector. For this we can use Hotelling’s T- squared test. Note that the closure of a vector $x$ with itself is the vector with values $1/d$, where $d$ is the number of components in the composition. Thus, when we are asking if the experiment had no effect we would expect to see perturbations that are all approximately $1/d$.

If we transform such a vector to ALR space, then all components should be approximately zero, since all of the ratios should be approximately constant, at **one** if all the perturbations are $1/d$.

```{r Hotelling}
MilkControl = as.matrix(MilkComposition[MilkComposition$Group == "Control", 1:6])
perturbs = matrix(0, nrow=30, ncol=6)
for(i in 1:30) perturbs[i,] = Closure(MilkControl[i+30,]/ MilkControl[i,])
colnames(perturbs) = colnames(MilkControl)[1:6]
## this is similar to, but not the same as the result in their paper
mnperturb = apply(perturbs, 2, mean)

## the Ng and Aitchison paper reports:
## [0.1595 0.1835 0.1599 0.1818 0.1458 0.1695]
## I get a similar, but not identical answer
round(mnperturb, digits = 4)


sdperturb = apply(perturbs, 2, sd)
##the difference here probably helps us understand what
##has changed - more Mf and Ca with less Na
mnperturb - rep(1/6,6)

##then compute the ALR for the perturbations
milkCalr = addLR(perturbs)

apply(milkCalr$x.alr, 2, mean)

##we can look at the variances as well
apply(milkCalr$x.alr, 2, sd)

##now for the test - results not at all in line with the paper

T2.test(milkCalr$x.alr)
```

We got results that are similar to those reported in the paper.

*This comparison shows that the alr mean is significantly different from zero at the 0.1 percent significance level and therefore that the centre of the perturbations is significantly different from the identity perturbation.* *We thus conclude that there is substantial evidence of a seasonal change which justifies the insistence on having a control group. The centre of the control group perturbations is \[0.1595 0.1835 0.1599 0.1818 0.1458 0.1695\].*


Now we will check out the perturbation data that was provided in the Aitchison undated manuscript.
Here we just start with the perturbations.  But we note that the perturbations are themselves compositional
and it may be useful to apply some of the basic tools.

Perturbations are useful here as ways to specify a model, that can then be tested.
Let $\xi$ denote the true perturbation vector that transforms a before measurement into an after measurement.
Then for each cow, we have $x_{Ai} = \xi \oplus x_{Bi}$. And the observed perturbations $p_{i} =  C\[x\_{Ai1}/x\_{Bi1}, \ldots, x\_{AiD} / x\_{BiD}\]$ are estimates of $\xi$.  Thus we could make some assumptions on the distribution of the $p+i$, such as the additive log Normal and use that as a basis for inference. This approach is likely to be more powerful than treating the data as a two sample comparison, since it blocks on individual.

```{r perturbdata}
data("cowperturbations")
controlP = as.matrix(cowperturbations[1:30, 2:7 ])
bfPalr = addLR(controlP)

## we can examine the covariance matrix of the alr transformed data
round(cov(bfPalr$x.alr), digits=3)

par(mfrow=c(2,3))
for(i in 1:6) plot(density(controlP[,i]), main=colnames(controlP)[i])

for(i in 1:5) plot(density(bfPalr$x.alr[,i]), main=colnames(controlP)[i])


controlV = variation(controlP, method="Pairwise")
# heatmap(controlV)
T2.test(bfPalr$x.alr)

##get control means
mnct = apply(bfPalr$x.alr, 2, mean)
ctlmns = addLRinv(matrix(mnct, nr=1), cnames=colnames(controlP))

## [pr mf ch Ca Na K]control = [0.1595 0.1835 0.1599 0.1818 0.1458 0.1695]
print(ctlmns, digits=4)

########################################
##now look at treated
########################################


treatP = as.matrix(cowperturbations[31:60,2:7])
treatPalr = addLR(treatP)

##get treated means - basically you have to get
##means in alr space and then invert back
mntrt = apply(treatPalr$x.alr, 2, mean)
trtmns = addLRinv(matrix(mntrt, nr=1), cnames=colnames(beforeP))

treatV = variation(treatP, method="Pairwise")
heatmap(treatV)
##[pr mf ch Ca Na K]treat = [0.1928 0.1416 0.1589 0.2309 0.1338 0.1420].
print(trtmns, digits=4)

par(mfrow=c(2,3))
for(i in 1:6) plot(density(treatP[,i]), main=colnames(treatP)[i])

## now K is the denominator for all of these
for(i in 1:5) plot(density(treatPalr$x.alr[,i]), main=colnames(treatP)[i])



##then we can find the perturbation that takes you from ctl to trt
## [pr mf ch Ca Na K]treat-control = [0.2015 0.1286 0.1656 0.2117 0.1529 0.1397]
##and probably subtract 1/6 from it
perturbation(trtmns, 1/ctlmns)


##note that this yields the values in the Aitchison and Ng paper
##the changes are much larger 
T2.test(treatPalr$x.alr)
```

## Consider a two sample test

Instead of computing the per individual perturbations one could also simply take the before and after data sets and compare them using Hotellings $T^2$ test. In some ways one might want to consider the two groups separately in order to study whether the covariance structure was similar or different at the two time points.

Here is where it might be good to try simulating and then comparing what we get by doing a paired-perturbation experiment versus doing a two sample experiment. That should help sort out both estimation and power.

```{r twosample}

Cbefore = as.matrix(MilkComposition[1:30,1:6])
Cafter = as.matrix(MilkComposition[31:60, 1:6])
Cb.arl = addLR(Cbefore)
Ca.arl = addLR(Cafter)

apply(Cb.arl$x.alr, 2, mean)
apply(Cb.arl$x.alr, 2, sd)

apply(Ca.arl$x.alr, 2, mean)
apply(Ca.arl$x.alr, 2, sd)

t2 = T2.test(x=Cb.arl$x.alr, y=Ca.arl$x.alr)
t2


```

In this case we do not get a significant result. This is likely due to the lack of accounting for pairing in the analysis.

## Will PCA or similar approaches help

Now the transformation to ALR space then allows us to try out different methods to try and understand the geometry of the data. We can, in that space look at principal components and see if they provide any insight.

```{r prcomp}
pr1 = prcomp(milkCalr$x.alr)

```

## Subcompositions

Ng and Aitchison also consider using perturbations to study subcomposition analysis. Their Section 3.2 is repeated below:

*Testing hypotheses of subcompositional stability.* While the above analysis was sufficient for the aim of the experiment we can use this example to illustrate another important form of compositional hypothesis, namely subcompositional stability. For example in geology in the study of the major-oxide chemistry of a series of rocks the question may arise as to whether certain oxides stay roughly constant relative to each other, in other words whether the subcomposition of these major oxides is stable. Let us place such a hypothesis within the framework of our milk composition problem. Suppose that it had been suggested that seasonal change would not affect the relative proportions of the minor elements (Ca, K, Na). This suggestion is clearly expressible as a perturbation hypothesis, namely that the perturbation is of the form $$
 \xi_C = [\xi_1, \xi_2, \xi_3, \xi_4, \xi_5, \xi_6 ]
$$ with the last three components corresponding to the minor elements. Under $H_0$ $alr(\xi_C)$ takes the form $[\eta_1, \eta_2, \eta_3, 0, 0 ]$ the hypothesis of subcompositional stability is simply a linear hypothesis within standard multivariate analysis and an exact test exists. We can, however apply an easier test. Since the hypothesis refers to the (Ca, K, Na) subcomposition we can confine consideration to the before-after perturbations associated with these subcompositions and ask whether these have an $alr$ mean of \[0 0\]. For the control group this gives a $T^2$ value of 3.52 to be compared against a 5 per cent critical value of 6.99; for the treatment group the $T^2$ value is 10.45. Thus a reasonable conclusion is that the (Ca, K, Na) subcomposition is stable against seasonal change but that there is significant instability in the presence of treatment.

In the code below we set up the test for the control group. But I do not get the same result as they did. So I am not sure just what is going on here.

```{r subcomp}
subcB = Cbefore[,c(4,5,6)]
subcA = Cafter[, c(4,5,6)]

subpert = matrix(0, nr=30, nc=3)
for(i in 1:30) subpert[i,] = Closure(MilkControl[i+30,c(4,5,6)]/ MilkControl[i,c(4,5,6)])
colnames(subpert) = colnames(subcB)
## 
mnsubpert = apply(subpert, 2, mean)

## close to the identify of 1/3
round(mnsubpert, digits = 4)

subalr = addLR(subpert)

subxx = T2.test(x=subalr$x.alr)
subxx


## how are these perturbation related to the subset of the whole group
##and the Hotelling's test is the same
sub2 = perturbs[,c(4,5,6)]
sub2alr = addLR(sub2)
sub2xx = T2.test(x=sub2alr$x.alr)

##while the perturbations are not the same  - the alrs are - which I think makes sense
##and gets at why/how we get a coherent analysis of subcompositions
##plot(sub2[,1], subpert[,1]) 
## plot(sub2alr$x.alr[,1], subalr$x.alr[,1])
```

By looking at the pairs plot for the perturbations we see that the negative correlation between Ca and Na is very strong while K seems to have a negative correlation with NA and a positive correlation with Ca.

One can also look at the raw data, via pairs, and see that there are strong negative correlations present in many of the variables. There appears to be some strong relationships between Pr, Mf and Ch as well are between Ca, Na and K, although the latter are not so obvious until you subset down just to those three.

```{r pairs}

pairs(subpert)

# pairs(perturbs)

# pairs(Cafter[,c(4,5,6)])

```
